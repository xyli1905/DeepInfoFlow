------------ Options -------------
activation: tanh
batch_size: 64
chkp_dir: ./checkpoints
classifier_net: LSTM
data_dir: ./data_proc/processed_data
dataset: IBNet
debug_dir: ./debug
dropout_rate: 0
encoder_net: 
full_mi: True
is_balanced: False
is_bidirectional: False
is_debug: False
is_emb_trainable: False
is_train: True
is_triplet: False
iter_size: 100000
load_epoch_C: 0
load_epoch_E: 0
loss_check_freq: -1
lr: 0.04
lr_C: 0.0001
lr_E: 0.04
margin: 0.01
max_epoch: 8000
max_epoch_C: 1
max_epoch_E: 6
max_loss_check: 10
model_type: baseline
momentum: 0.9
num_workers: 4
number_layers: 1
number_workers: 0
pretrained_weight_name: glove.pkl
results_dir: ./results
round_num: 1
save_freq: 1
save_root_dir: ./results
tag: null
test_data_name: test_mat.pkl
threshold: 0.5
train_data_name: train_mat.pkl
valid_num: 100000
vocab_name: vocab.pkl
weight_decay: 0.9
-------------- End ----------------
